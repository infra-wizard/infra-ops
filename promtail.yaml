# promtail-values.yaml
config:
  clients:
    - url: http://loki-gateway.loki.svc.cluster.local/loki/api/v1/push
  
  snippets:
    scrapeConfigs: |
      - job_name: kubernetes-pods
        kubernetes_sd_configs:
          - role: pod
        relabel_configs:
          # Add node name
          - action: replace
            source_labels: [__meta_kubernetes_pod_node_name]
            target_label: node_name
          
          # Add namespace
          - action: replace
            source_labels: [__meta_kubernetes_namespace]
            target_label: namespace
          
          # Add pod name
          - action: replace
            source_labels: [__meta_kubernetes_pod_name]
            target_label: pod
          
          # Add container name
          - action: replace
            source_labels: [__meta_kubernetes_pod_container_name]
            target_label: container
          
          # Add app label if exists
          - action: replace
            source_labels: [__meta_kubernetes_pod_label_app]
            target_label: app
            
          # Add service label if exists
          - action: replace
            source_labels: [__meta_kubernetes_pod_label_service]
            target_label: service
          
          # Set the correct log path - FIXED
          - action: replace
            replacement: /var/log/pods/*$1/*.log
            separator: /
            source_labels: [__meta_kubernetes_pod_uid, __meta_kubernetes_pod_container_name]
            target_label: __path__
        
        pipeline_stages:
          # Handle different log formats
          - match:
              selector: '{stream="stdout"}'
              stages:
                # Try to parse as JSON first (for structured logs)
                - json:
                    expressions:
                      log: log
                      message: message
                      level: level
                      timestamp: timestamp
                      time: time
                    drop_malformed: true
                
                # If JSON parsing fails, treat as plain text
                - output:
                    source: log
          
          # Handle stderr separately
          - match:
              selector: '{stream="stderr"}'
              stages:
                - output:
                    source: message
          
          # Extract log level from unstructured logs
          - regex:
              expression: '(?i)(?P<extracted_level>debug|info|warn|warning|error|fatal|trace)'
              source: message
          
          # Add extracted level as label
          - labels:
              extracted_level:
          
          # Parse timestamps if available
          - match:
              selector: '{extracted_level=~".+"}'
              stages:
                - timestamp:
                    source: timestamp
                    format: RFC3339Nano
                    fallback_formats:
                      - "2006-01-02 15:04:05"
                      - "2006-01-02T15:04:05Z"
                      - "2006-01-02T15:04:05.999999999Z07:00"

# Security context - needed to read log files
securityContext:
  runAsUser: 0
  runAsGroup: 0
  runAsNonRoot: false
  privileged: true

# Service account and RBAC
serviceAccount:
  create: true

rbac:
  create: true
  pspEnabled: false

# Tolerations to run on all nodes
tolerations:
  - operator: Exists
    effect: NoSchedule
  - operator: Exists
    effect: NoExecute

# Resources
resources:
  requests:
    cpu: 100m
    memory: 128Mi
  limits:
    cpu: 500m
    memory: 512Mi

# Mount host paths
volumes:
  - name: pods
    hostPath:
      path: /var/log/pods
  - name: containers
    hostPath:
      path: /var/lib/docker/containers

volumeMounts:
  - name: pods
    mountPath: /var/log/pods
    readOnly: true
  - name: containers
    mountPath: /var/lib/docker/containers
    readOnly: true

# Deploy as DaemonSet
daemonset:
  enabled: true
